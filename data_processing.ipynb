{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "CHEMIN = \"C:/Users/mathy/OneDrive/Bureau/EthicsFinance\" # A changer selon l'endroit où vous clonez le repo git\n",
    "esg_grade = pd.read_csv(f'{CHEMIN}/Score ESG brut.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_grade = esg_grade.dropna(subset=['ISSUER_EQUITY_TICKER', 'Groupe Industrie GICS', 'Score ESG brut'])\n",
    "esg_grade = esg_grade.drop(columns=['Pays', 'Date de Scoring', 'Identifiant Bloomberg Company', 'Identifiant sous industrie GICS', \"Nom de l'émetteur\"])\n",
    "esg_grade[\"ISSUER_EQUITY_TICKER\"] = esg_grade[\"ISSUER_EQUITY_TICKER\"].str.strip().str.replace(r'US$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_grade = esg_grade[~esg_grade[\"ISSUER_EQUITY_TICKER\"].str.contains(r'\\d')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_60_percent = esg_grade.sort_values(\"Score ESG brut\", ascending=False)\n",
    "top_60_percent = top_60_percent.head(int(0.6 * len(esg_grade)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_grade[\"ISSUER_EQUITY_TICKER\"] = esg_grade[\"ISSUER_EQUITY_TICKER\"].str.split().str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "end_date = datetime.today().date()\n",
    "start_date = end_date - timedelta(days=3*365)\n",
    "\n",
    "historical_data = {}\n",
    "\n",
    "for ticker in esg_grade[\"ISSUER_EQUITY_TICKER\"].unique():\n",
    "    try:\n",
    "        # Essayer de récupérer les données\n",
    "        data = yf.download(ticker, start=start_date, end=end_date, interval=\"1d\")\n",
    "        if data.empty:\n",
    "            print(f\"Aucune donnée pour le ticker {ticker}.\")\n",
    "            continue\n",
    "        data[\"Ticker\"] = ticker\n",
    "        historical_data[ticker] = data\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur pour le ticker {ticker} : {e}\")\n",
    "\n",
    "df_all_prices = pd.concat(historical_data.values())\n",
    "\n",
    "\n",
    "df_all_prices = df_all_prices.reset_index()\n",
    "\n",
    "df_all_prices.to_csv(f'{CHEMIN}/price_ticker.csv')\n",
    "print(df_all_prices.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "fichier_final = pd.read_csv('C:/Users/mathy/OneDrive/Bureau/EthicsFinance/price_ticker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier_final = fichier_final.dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathy\\AppData\\Local\\Temp\\ipykernel_10648\\3638717748.py:2: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  daily_returns = fichier_final.pct_change()\n"
     ]
    }
   ],
   "source": [
    "fichier_final = fichier_final[-1:].apply(pd.to_numeric, errors='coerce')\n",
    "daily_returns = fichier_final.pct_change()\n",
    "\n",
    "# Calcul du rendement moyen pour chaque action\n",
    "mean_returns = daily_returns.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_returns = mean_returns.sort_values(ascending=False)\n",
    "\n",
    "top_n = int(len(sorted_returns) * 0.5)\n",
    "\n",
    "# Garder les 50% du haut\n",
    "top_50_percent = sorted_returns.head(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ticker_names = top_50_percent.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ticker_names = pd.DataFrame(top_ticker_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ticker_names.to_csv(f'{CHEMIN}/tickers_finaux.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Spécifie le chemin vers le dossier contenant les fichiers Excel\n",
    "chemin_dossier = 'C:/Users/mathy/OneDrive/Bureau/Weightings'\n",
    "\n",
    "# Récupère tous les fichiers Excel dans le dossier\n",
    "fichiers = [f for f in os.listdir(chemin_dossier) if f.endswith(('.xls', '.xlsx'))]\n",
    "\n",
    "# Liste pour stocker les DataFrames\n",
    "liste_df = []\n",
    "\n",
    "for fichier in fichiers:\n",
    "    # Extrait le trimestre et l'année à partir du nom du fichier (ex: \"1_2020\")\n",
    "    nom_sans_extension = os.path.splitext(fichier)[0]\n",
    "    date_trimestre = nom_sans_extension  # ou fais un traitement plus fin si besoin\n",
    "\n",
    "    # Charge le fichier Excel\n",
    "    chemin_complet = os.path.join(chemin_dossier, fichier)\n",
    "    df = pd.read_excel(chemin_complet)\n",
    "\n",
    "    # Ajoute la colonne \"date_trimestre\"\n",
    "    df[\"date_trimestre\"] = date_trimestre\n",
    "\n",
    "    # Ajoute au tableau principal\n",
    "    liste_df.append(df)\n",
    "\n",
    "# Concatène tous les DataFrames\n",
    "df_final = pd.concat(liste_df, ignore_index=True)\n",
    "\n",
    "# (optionnel) Sauvegarde le résultat\n",
    "df_final.to_excel('bench_concat.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date_trimestre  portfolio_return\n",
      "0          1_2020        -22.093824\n",
      "1          2_2020         17.721106\n",
      "2          3_2020          0.894649\n",
      "3          4_2020         14.701741\n",
      "4          1_2021          9.946863\n",
      "5          2_2021          5.498201\n",
      "6          3_2021          0.013173\n",
      "7          4_2021          6.079225\n",
      "8          2_2022        -16.925947\n",
      "9          3_2022         -3.805916\n",
      "10         4_2022         13.259394\n",
      "11         1_2023         13.238669\n",
      "12         2_2023          1.671141\n",
      "13         3_2023         -3.838787\n",
      "14         4_2023          8.521958\n",
      "15         1_2024         11.748588\n",
      "16         2_2024         -2.431711\n",
      "17         3_2024          5.430800\n",
      "18         4_2024         -2.218341\n",
      "19         1_2025          9.488661\n"
     ]
    }
   ],
   "source": [
    "# Assure que date_trimestre est triée dans l’ordre\n",
    "df_final['date_trimestre'] = pd.Categorical(df_final['date_trimestre'],\n",
    "                                             categories=sorted(df_final['date_trimestre'].unique(), key=lambda x: (int(x.split('_')[1]), int(x.split('_')[0]))),\n",
    "                                             ordered=True)\n",
    "\n",
    "# Trie par trimestre\n",
    "df_final = df_final.sort_values('date_trimestre')\n",
    "\n",
    "# Crée un dictionnaire pour stocker les returns trimestriels\n",
    "returns = {}\n",
    "\n",
    "# Liste des trimestres triés\n",
    "trimestres = df_final['date_trimestre'].cat.categories.tolist()\n",
    "\n",
    "# Boucle sur les paires de trimestres (t-1, t)\n",
    "for i in range(1, len(trimestres)):\n",
    "    t_prev = trimestres[i - 1]\n",
    "    t_curr = trimestres[i]\n",
    "    \n",
    "    df_prev = df_final[df_final['date_trimestre'] == t_prev]\n",
    "    df_curr = df_final[df_final['date_trimestre'] == t_curr]\n",
    "\n",
    "    # Merge sur un identifiant commun, ici on suppose qu’il y a une colonne 'asset' (le nom de l'actif)\n",
    "    df_merged = pd.merge(df_curr, df_prev, on='Ticker', suffixes=('_curr', '_prev'))\n",
    "\n",
    "    # Calcul du return pondéré du portefeuille\n",
    "    weighted_return = ((df_merged['Price_curr'] / df_merged['Price_prev']) - 1) * df_merged['Weight_curr']\n",
    "    \n",
    "    portfolio_return = weighted_return.sum()\n",
    "    returns[t_curr] = portfolio_return\n",
    "\n",
    "# Transforme en DataFrame pour affichage\n",
    "df_returns = pd.DataFrame(list(returns.items()), columns=['date_trimestre', 'portfolio_return'])\n",
    "print(df_returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns.to_excel('bench_non_esg.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture de la liste de tickers à conserver\n",
    "tickers = pd.read_csv(\"tickers_finaux.csv\")  # ou pd.read_csv(\"tickers.csv\")\n",
    "tickers_faysal = pd.read_excel(\"bench_concat.xlsx\") \n",
    "\n",
    "# On suppose que la colonne contenant les tickers s'appelle 'Ticker' dans les deux fichiers\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_faysal['Tickers'] = tickers_faysal['Tickers'].str.replace(' Equity', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = tickers_faysal.merge(tickers, on='Tickers', how='inner')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
